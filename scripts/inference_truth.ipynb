{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install --upgrade jax\n",
    "# !pip install --upgrade keras-nlp\n",
    "# !pip install --upgrade keras-cv\n",
    "# !pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 11:41:01.194632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import util\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from toloboy.toloboy import RGB2LAB, from_LAB_to_RGB_img\n",
    "from tqdm import tqdm\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "from skimage.color import deltaE_ciede2000\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions/classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def mse(imageA, imageB, nband = 3):\n",
    "# \t# the 'Mean Squared Error' between the two images is the\n",
    "# \t# sum of the squared difference between the two images;\n",
    "# \t# NOTE: the two images must have the same dimension\n",
    "# \terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "# \terr /= float(imageA.shape[0] * imageA.shape[1] * nband)\n",
    "\t\n",
    "# \t# return the MSE, the lower the error, the more \"similar\"\n",
    "# \t# the two images are\n",
    "# \treturn err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmse(imageA, imageB, nband):\n",
    "# \t# the 'Root Mean Squared Error' between the two images is the\n",
    "# \t# sum of the squared difference between the two images;\n",
    "# \t# NOTE: the two images must have the same dimension\n",
    "# \terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "# \terr /= float(imageA.shape[0] * imageA.shape[1] * nband)\n",
    "# \terr = np.sqrt(err)\n",
    "# \treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mae(imageA, imageB, bands):\n",
    "\t# the 'Mean Absolute Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum(np.abs(imageA.astype(\"float\") - imageB.astype(\"float\")))\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1] * bands)\n",
    "\treturn err\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def psnr(img1, img2):\n",
    "    # Compute The peak signal-to-noise ratio (PSNR)\n",
    "    # Higher PSNR values indicate a higher quality of the predicted image.\n",
    "    mse = np.mean( (img1.astype(\"float\") - img2.astype(\"float\")) ** 2 )\n",
    "    # print(mse)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_e_cie2000(img0_rgb,imag1_RGB,Kl=1, KC=1, KH=1):\n",
    "    \n",
    "    Lab1 = cv2.cvtColor(img0_rgb, cv2.COLOR_BGR2Lab)\n",
    "    Lab2 = cv2.cvtColor(imag1_RGB, cv2.COLOR_BGR2Lab)\n",
    "    L1, a1, b1 = cv2.split(Lab1)\n",
    "    L2, a2, b2 = cv2.split(Lab2)\n",
    "    \n",
    "    \n",
    "    delta=deltaE_ciede2000(L1,L2, Kl, KC, KH)\n",
    "    #print(len(delta))\n",
    "    \n",
    "    return np.mean(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwisstopoDataset:\n",
    "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32, shuffle=False):\n",
    "        self.img_indx = img_indx\n",
    "        self.transform = transform\n",
    "        self.large_dataset = large_dataset\n",
    "        self.return_label = return_label\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Set the appropriate port based on the dataset size\n",
    "        self.port = 1986 if self.large_dataset else 1985\n",
    "\n",
    "        # Load metadata\n",
    "        self.metadata_file = self._load_metadata()\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
    "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "\n",
    "    def _fetch_image(self, img_id):\n",
    "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
    "        response = requests.get(img_in_server_link)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "\n",
    "    def _process_image(self, img_id):\n",
    "        image = self._fetch_image(img_id)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image = image / 255.0  # Default normalization\n",
    "        return image\n",
    "\n",
    "    def _get_label(self, idx):\n",
    "        return self.metadata_file[\"class\"].iloc[idx]\n",
    "\n",
    "    def _generator(self):\n",
    "        if self.shuffle:\n",
    "            img_indices = np.random.permutation(len(self.img_indx))\n",
    "        else:\n",
    "            img_indices = self.img_indx\n",
    "\n",
    "        for idx in range(len(self.img_indx)):\n",
    "            image = self._process_image(self.img_indx[idx])\n",
    "            L, AB = image  # Unpack the transformed image\n",
    "            if self.return_label:\n",
    "                label = self._get_label(idx)\n",
    "                yield (L, AB), label\n",
    "            else:\n",
    "                yield L, AB\n",
    "\n",
    "    def get_dataset(self):\n",
    "        # Dynamically infer the shapes of L and AB channels\n",
    "        def _dynamic_output_signature():\n",
    "            example_image = self._fetch_image(self.img_indx[0])\n",
    "            example_transformed = self.transform(example_image)\n",
    "            L, AB = example_transformed\n",
    "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
    "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
    "            if self.return_label:\n",
    "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "            else:\n",
    "                return (L_shape, AB_shape)\n",
    "\n",
    "        output_signature = _dynamic_output_signature()\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
    "        dataset = dataset.batch(self.batch_size, drop_remainder=True) # use drop reminder to have same size always\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LTransformation(object):\n",
    "    def __init__(self, contrast_range=(0.9, 1), brightness_range=(-0.05, 0.20), noise_var_range=(0, 0.005)):\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_range = brightness_range\n",
    "        self.noise_var_range = noise_var_range\n",
    "\n",
    "    def _apply_factor(self, L_channel, contrast_factor, brightness_factor):\n",
    "        # Apply adjusted brightness and contrast to the L channel\n",
    "        L_adjusted = contrast_factor * L_channel + brightness_factor\n",
    "\n",
    "        # Clip adjusted L channel to [0, 1]\n",
    "        L_adjusted = np.clip(L_adjusted, 0, 1)\n",
    "\n",
    "        return L_adjusted\n",
    "\n",
    "    def _apply_noise(self, L_channel, noise_var):\n",
    "        # Apply Gaussian noise to the L channel\n",
    "        L_noisy = util.random_noise(L_channel, mode='gaussian', var=noise_var)\n",
    "\n",
    "        # Clip noisy L channel to [0, 1]\n",
    "        L_noisy = np.clip(L_noisy, 0, 1)\n",
    "\n",
    "        return L_noisy\n",
    "\n",
    "    def _randomize_factors(self):\n",
    "        return np.random.uniform(*self.brightness_range), np.random.uniform(*self.contrast_range)\n",
    "\n",
    "    def _randomize_noise_var(self):\n",
    "        return np.random.uniform(*self.noise_var_range)\n",
    "\n",
    "    def __call__(self, L_channel):\n",
    "        while True:\n",
    "            brightness_factor, contrast_factor = self._randomize_factors()\n",
    "            noise_var = self._randomize_noise_var()\n",
    "\n",
    "            # Apply adjusted brightness and contrast to the L channel\n",
    "            L_adjusted = self._apply_factor(L_channel, contrast_factor, brightness_factor)\n",
    "\n",
    "            # Apply Gaussian noise to the L channel\n",
    "            L_augmented = self._apply_noise(L_adjusted, noise_var)\n",
    "\n",
    "            # Check if values are within range\n",
    "            if 0 <= np.min(L_augmented) <= np.max(L_augmented) <= 1:\n",
    "                break\n",
    "\n",
    "        return L_augmented, contrast_factor, brightness_factor, noise_var\n",
    "\n",
    "def convert_RGB_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs\n",
    "\n",
    "\n",
    "def convert_RGB__and_augment_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    # Apply LTransformation to the L channel\n",
    "    L_transformation = LTransformation()\n",
    "    L_augmented, _, _, _ = L_transformation(L.reshape((sz_x, sz_y)))\n",
    "\n",
    "    train_input[:, :, 0] = L_augmented\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_transform(image):\n",
    "    L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_and_augment_transform(image):\n",
    "    if np.random.rand() < 0.25:  # only apply augmentation to 25% of the data\n",
    "        L, AB = convert_RGB__and_augment_to_feed_model(image)\n",
    "    else:\n",
    "        L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check info from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
    "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
    "\n",
    "NOTE: the following are links stored in a private server, jet they are still publically available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10008 entries, 0 to 10007\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   img_id      10008 non-null  int64  \n",
      " 1   img_name    10008 non-null  object \n",
      " 2   latitude    10008 non-null  float64\n",
      " 3   longitude   10008 non-null  float64\n",
      " 4   zoom_level  10008 non-null  int64  \n",
      " 5   class       10008 non-null  int64  \n",
      " 6   link        10008 non-null  object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 625.5+ KB\n"
     ]
    }
   ],
   "source": [
    "is_large_dataset = True\n",
    "\n",
    "if is_large_dataset:\n",
    "    server_port = 1986 # Large dataset of ~10K images\n",
    "else:\n",
    "    server_port = 1985 # Large dataset of ~10K images\n",
    "# server_port = 1985 # initial dataset of 3.6K images\n",
    "\n",
    "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
    "\n",
    "\n",
    "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "metadata_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Train, Valid and Test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
    "\n",
    "The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size fo the train dataset is: 7005.\n",
      "the size fo the validation dataset is: 2902.\n",
      "the size fo the test dataset is: 101.\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
    "\n",
    "rand_state = 9898\n",
    "train_ratio = 0.70\n",
    "validation_ratio = 0.29\n",
    "test_ratio = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
    "\n",
    "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1\n",
    "\n",
    "# Instantiate the dataset\n",
    "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_loader = SwisstopoDataset(x_test,\n",
    "                           transform=convert_to_LAB_transform,\n",
    "                           large_dataset=True,\n",
    "                           return_label=True,\n",
    "                           batch_size=b_size,\n",
    "                           shuffle=False)\n",
    "\n",
    "# train_dataset = train_dataset_loader.get_dataset()\n",
    "test_dataset = test_dataset_loader.get_dataset()\n",
    "# valid_dataset = valid_dataset_loader.get_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tf.data.Dataset\n",
    "# Iterate over the dataset\n",
    "# for batch in test_dataset:\n",
    "#     # (L_channel, AB_channels), labels = batch # print with labels\n",
    "#     # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
    "#     L_channel, AB_channels= batch # print without labels\n",
    "#     print(L_channel.shape, AB_channels.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional info about the base *Hyper-U-Net* model can be found at the following sources:\n",
    "\n",
    "- link to [original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9604844/)\n",
    "\n",
    "- link to [repository](https://github.com/3DOM-FBK/Hyper_U_Net?tab=readme-ov-file)\n",
    "\n",
    "- link to [model](\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
    "\n",
    "NOTE: This will download a multiples large files to your device in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if model is in the current directory otherwise download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: base_model\n",
      "URL: https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\n",
      "\n",
      "Model Name: HyperUnet_retrain_augmented_noise_corrected_Adam\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_Adam/HyperUnet_retrain_augmented_noise_corrected_Adam_ckpt_epoch30_valloss0.0249.keras\n",
      "\n",
      "Model Name: HyperUnet_retrain_augmented_noise_corrected_rmsprop\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_rmsprop/HyperUnet_retrain_augmented_noise_corrected_rmsprop_ckpt_epoch30_valloss0.0248.keras\n",
      "\n",
      "Model Name: HyperUnet_retrain_no_augmented_corrected_Adam\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_no_augmented_corrected_Adam/HyperUnet_retrain_no_augmented_corrected_Adam_ckpt_epoch30_valloss0.0243.keras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_sources = {\n",
    "    \"model_name\": [\n",
    "        \"base_model\",\n",
    "        # \"HyperUnet_retrained_30e\",\n",
    "        # \"HyperUnet_retrain_augmented_30e\",\n",
    "        # \"HyperUnet_retrain_augmented_noise_25e\",\n",
    "        \"HyperUnet_retrain_augmented_noise_corrected_Adam\",\n",
    "        \"HyperUnet_retrain_augmented_noise_corrected_rmsprop\",\n",
    "        \"HyperUnet_retrain_no_augmented_corrected_Adam\",\n",
    "          ],\n",
    "    \"url\": [\n",
    "        \"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrained_30e/HyperUnet_retrain1.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented/HyperUnet_retrain_augmented_epoch30_valloss0.0011.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise/HyperUnet_retrain_augmented_noise_ckpt_epoch25_valloss0.0010.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_Adam/HyperUnet_retrain_augmented_noise_corrected_Adam_ckpt_epoch30_valloss0.0249.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_rmsprop/HyperUnet_retrain_augmented_noise_corrected_rmsprop_ckpt_epoch30_valloss0.0248.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_no_augmented_corrected_Adam/HyperUnet_retrain_no_augmented_corrected_Adam_ckpt_epoch30_valloss0.0243.keras\",\n",
    "        ],\n",
    "    \"extension\": [\n",
    "        \"h5\",\n",
    "        # \"keras\",\n",
    "        # \"keras\",\n",
    "        # \"keras\",\n",
    "        \"keras\",\n",
    "        \"keras\",\n",
    "        \"keras\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    model_name = models_sources[\"model_name\"][i]\n",
    "    url = models_sources[\"url\"][i]\n",
    "    print(f\"Model Name: {model_name}\\nURL: {url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    file_name = models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]\n",
    "    if not os.path.exists(os.path.join(os.curdir,file_name)):\n",
    "        model_url = models_sources['url'][i]\n",
    "        !wget -O {file_name}  \"$model_url\"\n",
    "    else:\n",
    "        print(\"########### No model to load, everything is in the current directory ##############\")\n",
    "    # !wget -O {models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]} {models_sources[\"url\"][i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** loading 'base_model.h5' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_augmented_noise_corrected_Adam.keras' *****\n",
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_augmented_noise_corrected_rmsprop.keras' *****\n",
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_no_augmented_corrected_Adam.keras' *****\n",
      "***** done *****\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {}\n",
    "\n",
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    file_name = models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]\n",
    "    # print(f\"{'*'*5} loading '{models_sources['model_name'][i]}' {'*'*5}\")\n",
    "    print(f\"{'*'*5} loading '{file_name}' {'*'*5}\")\n",
    "    models[models_sources[\"model_name\"][i]] = load_model(file_name)\n",
    "    print(f\"{'*'*5} done {'*'*5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot inference and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
