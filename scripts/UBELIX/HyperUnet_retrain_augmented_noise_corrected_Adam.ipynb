{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPhrWUfPtbOB"
      },
      "source": [
        "# Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nOu67AemtbOD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
            "  Referenced from: <103AD477-408D-3C2F-84B8-B7B8FFF88455> /Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/torchvision/image.so\n",
            "  Expected in:     <D1E1EC61-A5AA-3BBA-94B8-043C751C8A50> /Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "2024-07-24 22:39:26.680489: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# %config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [5, 5]\n",
        "from glob import glob\n",
        "import os\n",
        "from copy import deepcopy\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from skimage import util\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# import albumentations as A\n",
        "# from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import v2, functional\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import Adam, rmsprop\n",
        "from warnings import warn\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow import image as tf_image\n",
        "from tensorflow import io as tf_io\n",
        "\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Lorenz's libs\n",
        "# import math\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "# from pyproj import Proj, Transformer\n",
        "import random\n",
        "# from tqdm import tqdm\n",
        "# import folium\n",
        "# from folium.plugins import MarkerCluster\n",
        "\n",
        "from toloboy.toloboy import RGB2LAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.16.2\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z49vV6iBtbOF"
      },
      "source": [
        "# Define helper functions/classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ISBDAJ7tbOF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LTransformation(object):\n",
        "    def __init__(self, contrast_range=(0.9, 1), brightness_range=(-0.05, 0.20), noise_var_range=(0, 0.005)):\n",
        "        self.contrast_range = contrast_range\n",
        "        self.brightness_range = brightness_range\n",
        "        self.noise_var_range = noise_var_range\n",
        "\n",
        "    def _apply_factor(self, L_channel, contrast_factor, brightness_factor):\n",
        "        # Apply adjusted brightness and contrast to the L channel\n",
        "        L_adjusted = contrast_factor * L_channel + brightness_factor\n",
        "\n",
        "        # Clip adjusted L channel to [0, 1]\n",
        "        L_adjusted = np.clip(L_adjusted, 0, 1)\n",
        "\n",
        "        return L_adjusted\n",
        "\n",
        "    def _apply_noise(self, L_channel, noise_var):\n",
        "        # Apply Gaussian noise to the L channel\n",
        "        L_noisy = util.random_noise(L_channel, mode='gaussian', var=noise_var)\n",
        "\n",
        "        # Clip noisy L channel to [0, 1]\n",
        "        L_noisy = np.clip(L_noisy, 0, 1)\n",
        "\n",
        "        return L_noisy\n",
        "\n",
        "    def _randomize_factors(self):\n",
        "        return np.random.uniform(*self.brightness_range), np.random.uniform(*self.contrast_range)\n",
        "\n",
        "    def _randomize_noise_var(self):\n",
        "        return np.random.uniform(*self.noise_var_range)\n",
        "\n",
        "    def __call__(self, L_channel):\n",
        "        while True:\n",
        "            brightness_factor, contrast_factor = self._randomize_factors()\n",
        "            noise_var = self._randomize_noise_var()\n",
        "\n",
        "            # Apply adjusted brightness and contrast to the L channel\n",
        "            L_adjusted = self._apply_factor(L_channel, contrast_factor, brightness_factor)\n",
        "\n",
        "            # Apply Gaussian noise to the L channel\n",
        "            L_augmented = self._apply_noise(L_adjusted, noise_var)\n",
        "\n",
        "            # Check if values are within range\n",
        "            if 0 <= np.min(L_augmented) <= np.max(L_augmented) <= 1:\n",
        "                break\n",
        "\n",
        "        return L_augmented, contrast_factor, brightness_factor, noise_var\n",
        "\n",
        "def convert_RGB_to_feed_model(img):\n",
        "    img = np.asarray(img)\n",
        "    sz_x = img.shape[0]\n",
        "    sz_y = img.shape[1]\n",
        "\n",
        "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
        "    train_input = np.zeros((sz_x, sz_y, 1))\n",
        "\n",
        "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
        "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
        "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
        "    L, A, B = RGB2LAB(R1, G1, B1)\n",
        "\n",
        "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
        "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
        "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
        "\n",
        "    return train_input, train_imgs\n",
        "\n",
        "\n",
        "def convert_RGB__and_augment_to_feed_model(img):\n",
        "    img = np.asarray(img)\n",
        "    sz_x = img.shape[0]\n",
        "    sz_y = img.shape[1]\n",
        "\n",
        "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
        "    train_input = np.zeros((sz_x, sz_y, 1))\n",
        "\n",
        "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
        "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
        "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
        "    L, A, B = RGB2LAB(R1, G1, B1)\n",
        "\n",
        "    # Apply LTransformation to the L channel\n",
        "    L_transformation = LTransformation()\n",
        "    L_augmented, _, _, _ = L_transformation(L.reshape((sz_x, sz_y)))\n",
        "\n",
        "    train_input[:, :, 0] = L_augmented\n",
        "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
        "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
        "\n",
        "    return train_input, train_imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQK5mzkJtbOF"
      },
      "source": [
        "# Define custom Dataset class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fhg4hXt7tbOF"
      },
      "outputs": [],
      "source": [
        "class SwisstopoDataset:\n",
        "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32, shuffle=False):\n",
        "        self.img_indx = img_indx\n",
        "        self.transform = transform\n",
        "        self.large_dataset = large_dataset\n",
        "        self.return_label = return_label\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Set the appropriate port based on the dataset size\n",
        "        self.port = 1986 if self.large_dataset else 1985\n",
        "\n",
        "        # Load metadata\n",
        "        self.metadata_file = self._load_metadata()\n",
        "\n",
        "    def _load_metadata(self):\n",
        "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
        "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
        "\n",
        "    def _fetch_image(self, img_id):\n",
        "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
        "        response = requests.get(img_in_server_link)\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        return image\n",
        "\n",
        "    def _process_image(self, img_id):\n",
        "        try:\n",
        "            image = self._fetch_image(img_id)\n",
        "        except Exception as e:\n",
        "            warn(f\"{'*'*5} Problem loading image id: {img_id} {'*'*5}\")\n",
        "            raise e\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            image = image / 255.0  # Default normalization\n",
        "        return image\n",
        "\n",
        "    def _get_label(self, idx):\n",
        "        return self.metadata_file[\"class\"].iloc[idx]\n",
        "\n",
        "    def _generator(self):\n",
        "        if self.shuffle:\n",
        "            img_indices = np.random.permutation(len(self.img_indx))\n",
        "        else:\n",
        "            img_indices = self.img_indx\n",
        "\n",
        "        for idx in range(len(self.img_indx)):\n",
        "            image = self._process_image(self.img_indx[idx])\n",
        "            L, AB = image  # Unpack the transformed image\n",
        "            if self.return_label:\n",
        "                label = self._get_label(idx)\n",
        "                yield (L, AB), label\n",
        "            else:\n",
        "                yield L, AB\n",
        "\n",
        "    def get_dataset(self):\n",
        "        # Dynamically infer the shapes of L and AB channels\n",
        "        def _dynamic_output_signature():\n",
        "            example_image = self._fetch_image(self.img_indx[0])\n",
        "            example_transformed = self.transform(example_image)\n",
        "            L, AB = example_transformed\n",
        "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
        "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
        "            if self.return_label:\n",
        "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
        "            else:\n",
        "                return (L_shape, AB_shape)\n",
        "\n",
        "        output_signature = _dynamic_output_signature()\n",
        "\n",
        "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True) # use drop reminder to have same size always\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_Pey9rtbOG"
      },
      "source": [
        "# Define transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oG6p8WLgtbOG"
      },
      "outputs": [],
      "source": [
        "def convert_to_LAB_transform(image):\n",
        "    L, AB = convert_RGB_to_feed_model(image)\n",
        "    return (L, AB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zk55GvJ-M3sb"
      },
      "outputs": [],
      "source": [
        "def convert_to_LAB_and_augment_transform(image):\n",
        "    if np.random.rand() < 0.25:  # only apply augmentation to 25% of the data\n",
        "        L, AB = convert_RGB__and_augment_to_feed_model(image)\n",
        "    else:\n",
        "        L, AB = convert_RGB_to_feed_model(image)\n",
        "    return (L, AB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbnPPtxItbOG"
      },
      "source": [
        "# Check info from the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sv3aDOqtbOG"
      },
      "source": [
        "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
        "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
        "\n",
        "NOTE: the following are links stored in a private server, jet they are still publically available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4m9m1QstbOG",
        "outputId": "60de97b0-b9e3-49a5-a4c8-4006956dc863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 12960 entries, 0 to 12959\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   img_id      12960 non-null  int64  \n",
            " 1   img_name    12960 non-null  object \n",
            " 2   latitude    12960 non-null  float64\n",
            " 3   longitude   12960 non-null  float64\n",
            " 4   zoom_level  12960 non-null  int64  \n",
            " 5   class       12960 non-null  int64  \n",
            " 6   link        12960 non-null  object \n",
            "dtypes: float64(2), int64(3), object(2)\n",
            "memory usage: 810.0+ KB\n"
          ]
        }
      ],
      "source": [
        "is_large_dataset = True\n",
        "\n",
        "if is_large_dataset:\n",
        "    server_port = 1986 # Large dataset of ~10K images\n",
        "else:\n",
        "    server_port = 1985 # Large dataset of ~10K images\n",
        "# server_port = 1985 # initial dataset of 3.6K images\n",
        "\n",
        "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
        "\n",
        "\n",
        "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
        "metadata_raw_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qdE4zTGtbOG"
      },
      "source": [
        "# Split the Train, Valid and Test subsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bixi8SetbOG"
      },
      "source": [
        "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
        "\n",
        "~~The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively~~\n",
        "\n",
        "The final ratio for the train, validation and test dastasets are: 59, 25 and 16 % respectively.\n",
        "\n",
        "NOTE: we add additonal ~3000 images for computing the FID score metrics, rusulting in roughly using 10K images for training/valiation (in a ratio of 70/30% repectively) and 3K images for testing. Total images used were 12960.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTY8A1yltbOG",
        "outputId": "c5f8eacf-71df-498c-e6b8-873bc8c86cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the size fo the train dataset is: 7602.\n",
            "the size fo the validation dataset is: 3258.\n",
            "the size fo the test dataset is: 2100.\n"
          ]
        }
      ],
      "source": [
        "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
        "\n",
        "rand_state = 9898\n",
        "\n",
        "train_ratio = 0.5866\n",
        "validation_ratio = 0.2514\n",
        "test_ratio = 0.162\n",
        "\n",
        "\n",
        "\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
        "\n",
        "# test is now 10% of the initial data set\n",
        "# validation is now 15% of the initial data set\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
        "\n",
        "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "b_size =64\n",
        "\n",
        "# Instantiate the dataset\n",
        "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
        "\n",
        "train_dataset_loader = SwisstopoDataset(x_train,\n",
        "                           transform=convert_to_LAB_and_augment_transform,\n",
        "                           large_dataset=True,\n",
        "                           return_label=False,\n",
        "                           batch_size=b_size,\n",
        "                           shuffle=True)\n",
        "\n",
        "valid_dataset_loader = SwisstopoDataset(x_val,\n",
        "                           transform=convert_to_LAB_transform,\n",
        "                           large_dataset=True,\n",
        "                           return_label=False,\n",
        "                           batch_size=b_size,\n",
        "                           shuffle=False)\n",
        "\n",
        "test_dataset_loader = SwisstopoDataset(x_test,\n",
        "                           transform=convert_to_LAB_transform,\n",
        "                           large_dataset=True,\n",
        "                           return_label=False,\n",
        "                           batch_size=b_size,\n",
        "                           shuffle=False)\n",
        "\n",
        "train_dataset = train_dataset_loader.get_dataset()\n",
        "test_dataset = test_dataset_loader.get_dataset()\n",
        "valid_dataset = valid_dataset_loader.get_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the tf.data.Dataset\n",
        "# Iterate over the dataset\n",
        "for batch in train_dataset:\n",
        "    # (L_channel, AB_channels), labels = batch # print with labels\n",
        "    # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
        "    L_channel, AB_channels= batch # print without labels\n",
        "    print(L_channel.shape, AB_channels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Dmdyh6tbOH"
      },
      "source": [
        "# Load \"base\" TF model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIFpWS05tbOH"
      },
      "source": [
        "Load base Hyper-U-Net model from the original source:\n",
        "\n",
        "- link to [original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9604844/)\n",
        "\n",
        "- link to [repository](https://github.com/3DOM-FBK/Hyper_U_Net?tab=readme-ov-file)\n",
        "\n",
        "- link to [model](\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
        "\n",
        "NOTE: This will download a .h5 file to your device in the current directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrain Hyper UNet (**with** Transformations)\n",
        "\n",
        "Here you start the training loop or resume training with the following logics:\n",
        "- search for model name \"folder\"\n",
        "\n",
        "if the model does not exist\n",
        "- create a new one and retrieve the *vanilla* HyperUnet model\n",
        "- create configuration for checkpoints (folders/frequency/names)\n",
        "- start trianin loop\n",
        "\n",
        "if the model exists but training was not finished:\n",
        "- find the filder with the checkpoints \n",
        "- resume training from last checkpoint until reaching the initial no of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******* the model 'HyperUnet_retrain_augmented_noise' was already initialize here *******.\n",
            "******* Finding last model to resume training *******\n",
            "Restoring model 'HyperUnet_retrain_augmented_noise' with last epoch = 8\n",
            "Fail to load model with error ---->>>> Unable to load model. Filepath is not an hdf5 file (or h5py is not available) or SavedModel. Received: filepath=None <<<<----\n"
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "name = \"HyperUnet_retrain_augmented_noise_corrected_Adam\"\n",
        "\n",
        "checkpoint_dir = os.path.abspath(\n",
        "    os.path.join(\n",
        "        os.curdir, \n",
        "        \"..\",\n",
        "        \"models\",\n",
        "        name,\n",
        "        )\n",
        "        )\n",
        "# checkpoint_dir = r\"/Volumes/Ruben/datasets/fetched_raw_imgs_via_api_full/Models/HyperUnet_retrain_augmented_noise\"\n",
        "model_ckpt_file_name = f\"{name}_ckpt_epoch{{epoch:02d}}_valloss{{val_loss:.4f}}.keras\"\n",
        "\n",
        "checkpoint_path = os.path.join(checkpoint_dir,\n",
        "                               model_ckpt_file_name)\n",
        "\n",
        "callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            checkpoint_path, \n",
        "            save_freq='epoch',\n",
        "            save_best_only=False,\n",
        "            save_weights_only = False,\n",
        "            verbose=1\n",
        "            ),\n",
        "            keras.callbacks.CSVLogger(os.path.join(checkpoint_dir, name + \"_\" + 'history.csv'), append=True )\n",
        "            ]\n",
        "\n",
        "# train_loss = []\n",
        "# val_loss = []\n",
        "# train_rmse = []\n",
        "# val_rmse = []\n",
        "\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "\n",
        "    print(f\"No model '{name}' found, training from scratch. n_epochs = {epochs}\")\n",
        "\n",
        "    print(f\"******* making new dir to store model @: '{checkpoint_dir}' *******\")\n",
        "\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "    print(\"******* Loading Base model *******\")\n",
        "\n",
        "    url = (\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
        "    filename=\"Hyper_U_Net.h5\"\n",
        "\n",
        "    if not os.path.exists(os.path.join(os.curdir, \"Hyper_U_Net.h5\")):\n",
        "        path, headers = urlretrieve(url, filename)\n",
        "    # for name, value in headers.items():\n",
        "    #     print(name, value)\n",
        "    # model1 = keras.models.load_model(os.path.join(os.curdir, \"Hyper_U_Net.h5\"))\n",
        "    # Load the saved model\n",
        "    loaded_model = tf.keras.models.load_model(\"Hyper_U_Net.h5\")\n",
        "\n",
        "    # Find the index of the last encoder layer\n",
        "    last_encoder_layer_index = loaded_model.layers.index(loaded_model.get_layer('max_pooling2d_4'))\n",
        "\n",
        "    # Freeze all layers up to the last encoder layer\n",
        "    for layer in loaded_model.layers[:last_encoder_layer_index + 1]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Function to count the number of parameters\n",
        "    def count_params(model, only_trainable=False):\n",
        "        if only_trainable:\n",
        "            return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "        else:\n",
        "            return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights + model.non_trainable_weights])\n",
        "\n",
        "    # Get the number of trainable and non-trainable parameters\n",
        "    trainable_params = count_params(loaded_model, only_trainable=True)\n",
        "    total_params = count_params(loaded_model)\n",
        "\n",
        "    print(f\"Trainable parameters: {trainable_params}\")\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "\n",
        "    # Display model summary\n",
        "    loaded_model.summary()\n",
        "\n",
        "    # Compile the model after freezing the encoder layers\n",
        "    # loaded_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-5, \n",
        "                                                             decay_steps=10,\n",
        "                                                             decay_rate=0.96)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    loaded_model.compile(\n",
        "        optimizer = opt,\n",
        "        # Adam(lr = 2e-6), \n",
        "        loss = 'mean_absolute_error', \n",
        "        metrics = ['RootMeanSquaredError']\n",
        "        )\n",
        "\n",
        "    \n",
        "    print(\"******* start training loop *******\")\n",
        "    history = loaded_model.fit(\n",
        "                train_dataset,\n",
        "                epochs=epochs,\n",
        "                validation_data=valid_dataset,\n",
        "                validation_steps=4,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "    print(\"******* Done with training *******\")\n",
        "\n",
        "else:\n",
        "\n",
        "    print(f\"******* the model '{name}' was already initialize here *******.\\n******* Finding last model to resume training *******\")\n",
        "    model_list = sorted(glob(os.path.join(checkpoint_dir, \"*.keras\")), \n",
        "                        key=lambda x: int([segment for segment in x.split('_') if 'epoch' in segment][0][-2:]))\n",
        "    \n",
        "    try:\n",
        "    \n",
        "        if len(model_list) > 0:\n",
        "            \n",
        "            last_model_path = model_list[-2]\n",
        "            last_epoch_found = int(last_model_path.split('_')[-2][-2:])\n",
        "            last_epoch_found_str = str(last_model_path.split('_')[-2][-2:]) # same thing as last_model_path bus as string\n",
        "            print(f\"Restoring model '{name}' with last epoch = {last_epoch_found}\")\n",
        "            # Restore the full model\n",
        "            print(\">>>>>>> here is before error: \",checkpoint_dir)\n",
        "            print(\">>>>>>> here is before error: \",model_ckpt_file_name)\n",
        "            # latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir, model_ckpt_file_name)\n",
        "            latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir, checkpoint_path)\n",
        "            # latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "            print(\">>>>>>> here passed: `tf.train.latest_checkpoint(checkpoint_dir, model_ckpt_file_name)` \")\n",
        "            restored_model = tf.keras.models.load_model(latest_checkpoint)\n",
        "            print(\">>>>>>> here passed: `tf.keras.models.load_model(latest_checkpoint)` \")\n",
        "            \n",
        "            # new_checkpoint_dir = os.path.join(checkpoint_dir, f\"retrained_from_epoch{last_epoch_found_str}\")\n",
        "            \n",
        "            # print(f\"new models will be stored @ the subfolder {new_checkpoint_dir}.\")\n",
        "            \n",
        "            epochs = epochs - last_epoch_found\n",
        "            \n",
        "            \n",
        "            print(f\"Resume training from last epoch. Remaining : {epochs} - {last_epoch_found} = {epochs - last_epoch_found}.\")\n",
        "            # loaded_model = tf.keras.models.load_model(last_model_path)\n",
        "            history = restored_model.fit(\n",
        "                train_dataset,\n",
        "                epochs=epochs,\n",
        "                validation_data=valid_dataset,\n",
        "                validation_steps=4,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1\n",
        "            )\n",
        "            print(\"******* Done with training *******\")\n",
        "        else:\n",
        "            print(f\"A folder with model name '{name}' was found but not model inside. \\nStarting training.\")\n",
        "            print(\"******* Loading Base model *******\")\n",
        "            url = (\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
        "            filename=\"Hyper_U_Net.h5\"\n",
        "\n",
        "            if not os.path.exists(os.path.join(os.curdir, \"Hyper_U_Net.h5\")):\n",
        "                path, headers = urlretrieve(url, filename)\n",
        "            # for name, value in headers.items():\n",
        "            #     print(name, value)\n",
        "            # model1 = keras.models.load_model(os.path.join(os.curdir, \"Hyper_U_Net.h5\"))\n",
        "            # Load the saved model\n",
        "            loaded_model = tf.keras.models.load_model(\"Hyper_U_Net.h5\")\n",
        "\n",
        "            # Find the index of the last encoder layer\n",
        "            last_encoder_layer_index = loaded_model.layers.index(loaded_model.get_layer('max_pooling2d_4'))\n",
        "\n",
        "            # Freeze all layers up to the last encoder layer\n",
        "            for layer in loaded_model.layers[:last_encoder_layer_index + 1]:\n",
        "                layer.trainable = False\n",
        "\n",
        "            # Function to count the number of parameters\n",
        "            def count_params(model, only_trainable=False):\n",
        "                if only_trainable:\n",
        "                    return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "                else:\n",
        "                    return np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights + model.non_trainable_weights])\n",
        "\n",
        "            # Get the number of trainable and non-trainable parameters\n",
        "            trainable_params = count_params(loaded_model, only_trainable=True)\n",
        "            total_params = count_params(loaded_model)\n",
        "\n",
        "            print(f\"Trainable parameters: {trainable_params}\")\n",
        "            print(f\"Total parameters: {total_params}\")\n",
        "\n",
        "            # Display model summary\n",
        "            loaded_model.summary()\n",
        "\n",
        "            # Compile the model after freezing the encoder layers\n",
        "            # loaded_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "            lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-5, \n",
        "                                                                    decay_steps=10,\n",
        "                                                                    decay_rate=0.96)\n",
        "            opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "            loaded_model.compile(\n",
        "                optimizer = opt,\n",
        "                # Adam(lr = 2e-6), \n",
        "                loss = 'mean_absolute_error', \n",
        "                metrics = ['RootMeanSquaredError']\n",
        "                )\n",
        "\n",
        "            \n",
        "            print(\"******* start training loop *******\")\n",
        "            history = loaded_model.fit(\n",
        "                        train_dataset,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=valid_dataset,\n",
        "                        validation_steps=4,\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=1\n",
        "                    )\n",
        "            print(\"******* Done with training *******\")\n",
        "        # else:\n",
        "        #     raise FileNotFoundError(f\"A folder with model name '{name}' was found but not model inside. Define what to do here!!!\")\n",
        "                \n",
        "        # history = loaded_model.fit(\n",
        "        #     train_dataset,\n",
        "        #     epochs=epochs,\n",
        "        #     validation_data=valid_dataset,\n",
        "        #     validation_steps=4,\n",
        "        #     callbacks=callbacks,\n",
        "        #     verbose=1\n",
        "        # )\n",
        "    # model_list = sorted(glob(os.path.join(checkpoint_dir, \"*.keras\")), \n",
        "    #                     key=lambda x: int([segment for segment in x.split('_') if 'epoch' in segment][0][-2:]))\n",
        "\n",
        "\n",
        "    # if len(model_list) > 0:\n",
        "    #     last_model_path = model_list[-2]\n",
        "    #     last_epoch_found = int(last_model_path.split('_')[-2][-2:])\n",
        "    #     print(f\"found model with last epoch = {last_epoch_found}\")\n",
        "    #     print(f\"Resume training from last epoch. Remaining : {epochs} - {last_epoch_found} = {epochs - last_epoch_found}.\")\n",
        "    #     epochs = epochs - last_epoch_found\n",
        "        # print(last_model_path)\n",
        "        # loaded_model.load_weights(last_model_path)\n",
        "        # latest = tf.train.latest_checkpoint(last_model_path)\n",
        "        # latest\n",
        "        # loaded_model.load_weights(latest)\n",
        "\n",
        "        # loaded_model = tf.keras.models.load_model(last_model_path)\n",
        "        # history = loaded_model.fit(\n",
        "        #     train_dataset,\n",
        "        #     epochs=epochs,\n",
        "        #     validation_data=valid_dataset,\n",
        "        #     validation_steps=4,\n",
        "        #     callbacks=callbacks,\n",
        "        #     verbose=1\n",
        "        # )\n",
        "    # else:\n",
        "    #     print(f\"No model found, training from scratch n_epochs = {epochs}\")\n",
        "        # history = loaded_model.fit(\n",
        "        #     train_dataset,\n",
        "        #     epochs=epochs,\n",
        "        #     validation_data=valid_dataset,\n",
        "        #     validation_steps=4,\n",
        "        #     callbacks=callbacks,\n",
        "        #     verbose=1\n",
        "        # )\n",
        "\n",
        "    except Exception as exc:\n",
        "        print(f'Fail to load model with error ---->>>> {exc} <<<<----')\n",
        "\n",
        "\n",
        "with open(os.path.join(checkpoint_dir, name + '_history_dict'), 'wb') as file:\n",
        "    pickle.dump(history.history, file)\n",
        "    print(f\"{'*' * 5} History file saved with pickle {'*' * 5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## start training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### recap from last checkpoint otherwise start a new training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checkpoint_dir = r\"/Volumes/Ruben/datasets/fetched_raw_imgs_via_api_full/Models/HyperUnet_retrain_augmented_noise\"\n",
        "# os.path.exists(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "# test_loss, test_accuracy = loaded_model.evaluate(test_dataset)\n",
        "# print(f'Test Loss: {test_loss}')\n",
        "# print(f'Test Accuracy: {test_accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the training evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig(os.path.join(checkpoint_dir, f'{name}_loss.png'), dpi=100)\n",
        "# plt.savefig(sys.stdout.buffer)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['RootMeanSquaredError'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_RootMeanSquaredError'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.savefig(os.path.join(checkpoint_dir, f'{name}_rmse.png'), dpi=100)\n",
        "# plt.savefig(sys.stdout.buffer)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"######### Training is done! yahoo!!!!! #########\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
