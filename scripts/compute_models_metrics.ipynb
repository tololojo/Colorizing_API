{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install --upgrade jax\n",
    "# !pip install --upgrade keras-nlp\n",
    "# !pip install --upgrade keras-cv\n",
    "# !pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 13:21:05.102480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "import os\n",
    "from urllib import request\n",
    "import numpy as np\n",
    "from skimage import util\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from toloboy.toloboy import RGB2LAB, from_LAB_to_RGB_img\n",
    "from tqdm import tqdm\n",
    "tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
    "from skimage.color import deltaE_ciede2000\n",
    "import cv2\n",
    "\n",
    "from numpy.random import shuffle\n",
    "from scipy.linalg import sqrtm\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions/classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def mse(imageA, imageB, nband = 3):\n",
    "# \t# the 'Mean Squared Error' between the two images is the\n",
    "# \t# sum of the squared difference between the two images;\n",
    "# \t# NOTE: the two images must have the same dimension\n",
    "# \terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "# \terr /= float(imageA.shape[0] * imageA.shape[1] * nband)\n",
    "\t\n",
    "# \t# return the MSE, the lower the error, the more \"similar\"\n",
    "# \t# the two images are\n",
    "# \treturn err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rmse(imageA, imageB, nband):\n",
    "# \t# the 'Root Mean Squared Error' between the two images is the\n",
    "# \t# sum of the squared difference between the two images;\n",
    "# \t# NOTE: the two images must have the same dimension\n",
    "# \terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "# \terr /= float(imageA.shape[0] * imageA.shape[1] * nband)\n",
    "# \terr = np.sqrt(err)\n",
    "# \treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mae(imageA, imageB, bands = 3):\n",
    "\t# the 'Mean Absolute Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum(np.abs(imageA.astype(\"float\") - imageB.astype(\"float\")))\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1] * bands)\n",
    "\treturn err\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def psnr(img1, img2):\n",
    "    # Compute The peak signal-to-noise ratio (PSNR)\n",
    "    # Higher PSNR values indicate a higher quality of the predicted image.\n",
    "    img1 = np.array(img1, dtype=np.float32)\n",
    "    img2 = np.array(img2, dtype=np.float32)\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    # print(mse)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_e_cie2000(img0_rgb,imag1_RGB,Kl=1, KC=1, KH=1):\n",
    "    \n",
    "    Lab1 = cv2.cvtColor(img0_rgb, cv2.COLOR_BGR2Lab)\n",
    "    Lab2 = cv2.cvtColor(imag1_RGB, cv2.COLOR_BGR2Lab)\n",
    "    L1, a1, b1 = cv2.split(Lab1)\n",
    "    L2, a2, b2 = cv2.split(Lab2)\n",
    "    \n",
    "    \n",
    "    delta=deltaE_ciede2000(L1,L2, Kl, KC, KH)\n",
    "    #print(len(delta))\n",
    "    \n",
    "    return np.mean(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwisstopoDataset:\n",
    "    def __init__(self, img_indx, transform=None, large_dataset=False, return_label=True, batch_size=32, shuffle=False):\n",
    "        self.img_indx = img_indx\n",
    "        self.transform = transform\n",
    "        self.large_dataset = large_dataset\n",
    "        self.return_label = return_label\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Set the appropriate port based on the dataset size\n",
    "        self.port = 1986 if self.large_dataset else 1985\n",
    "\n",
    "        # Load metadata\n",
    "        self.metadata_file = self._load_metadata()\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        raw_data_csv_file_link = f\"https://perritos.myasustor.com:{self.port}/metadata.csv\"\n",
    "        return pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "\n",
    "    def _fetch_image(self, img_id):\n",
    "        img_in_server_link = f\"https://perritos.myasustor.com:{self.port}/data/img_id_{img_id}.jpg\"\n",
    "        response = requests.get(img_in_server_link)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "\n",
    "    def _process_image(self, img_id):\n",
    "        image = self._fetch_image(img_id)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            image = image / 255.0  # Default normalization\n",
    "        return image\n",
    "\n",
    "    def _get_label(self, idx):\n",
    "        return self.metadata_file[\"class\"].iloc[idx]\n",
    "\n",
    "    def _generator(self):\n",
    "        if self.shuffle:\n",
    "            img_indices = np.random.permutation(len(self.img_indx))\n",
    "        else:\n",
    "            img_indices = self.img_indx\n",
    "\n",
    "        for idx in range(len(self.img_indx)):\n",
    "            image = self._process_image(self.img_indx[idx])\n",
    "            L, AB = image  # Unpack the transformed image\n",
    "            if self.return_label:\n",
    "                label = self._get_label(idx)\n",
    "                yield (L, AB), label\n",
    "            else:\n",
    "                yield L, AB\n",
    "\n",
    "    def get_dataset(self):\n",
    "        # Dynamically infer the shapes of L and AB channels\n",
    "        def _dynamic_output_signature():\n",
    "            example_image = self._fetch_image(self.img_indx[0])\n",
    "            example_transformed = self.transform(example_image)\n",
    "            L, AB = example_transformed\n",
    "            L_shape = tf.TensorSpec(shape=L.shape, dtype=tf.float32)\n",
    "            AB_shape = tf.TensorSpec(shape=AB.shape, dtype=tf.float32)\n",
    "            if self.return_label:\n",
    "                return ((L_shape, AB_shape), tf.TensorSpec(shape=(), dtype=tf.int64))\n",
    "            else:\n",
    "                return (L_shape, AB_shape)\n",
    "\n",
    "        output_signature = _dynamic_output_signature()\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self._generator, output_signature=output_signature)\n",
    "        dataset = dataset.batch(self.batch_size, drop_remainder=True) # use drop reminder to have same size always\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LTransformation(object):\n",
    "    def __init__(self, contrast_range=(0.9, 1), brightness_range=(-0.05, 0.20), noise_var_range=(0, 0.005)):\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_range = brightness_range\n",
    "        self.noise_var_range = noise_var_range\n",
    "\n",
    "    def _apply_factor(self, L_channel, contrast_factor, brightness_factor):\n",
    "        # Apply adjusted brightness and contrast to the L channel\n",
    "        L_adjusted = contrast_factor * L_channel + brightness_factor\n",
    "\n",
    "        # Clip adjusted L channel to [0, 1]\n",
    "        L_adjusted = np.clip(L_adjusted, 0, 1)\n",
    "\n",
    "        return L_adjusted\n",
    "\n",
    "    def _apply_noise(self, L_channel, noise_var):\n",
    "        # Apply Gaussian noise to the L channel\n",
    "        L_noisy = util.random_noise(L_channel, mode='gaussian', var=noise_var)\n",
    "\n",
    "        # Clip noisy L channel to [0, 1]\n",
    "        L_noisy = np.clip(L_noisy, 0, 1)\n",
    "\n",
    "        return L_noisy\n",
    "\n",
    "    def _randomize_factors(self):\n",
    "        return np.random.uniform(*self.brightness_range), np.random.uniform(*self.contrast_range)\n",
    "\n",
    "    def _randomize_noise_var(self):\n",
    "        return np.random.uniform(*self.noise_var_range)\n",
    "\n",
    "    def __call__(self, L_channel):\n",
    "        while True:\n",
    "            brightness_factor, contrast_factor = self._randomize_factors()\n",
    "            noise_var = self._randomize_noise_var()\n",
    "\n",
    "            # Apply adjusted brightness and contrast to the L channel\n",
    "            L_adjusted = self._apply_factor(L_channel, contrast_factor, brightness_factor)\n",
    "\n",
    "            # Apply Gaussian noise to the L channel\n",
    "            L_augmented = self._apply_noise(L_adjusted, noise_var)\n",
    "\n",
    "            # Check if values are within range\n",
    "            if 0 <= np.min(L_augmented) <= np.max(L_augmented) <= 1:\n",
    "                break\n",
    "\n",
    "        return L_augmented, contrast_factor, brightness_factor, noise_var\n",
    "\n",
    "def convert_RGB_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    train_input[:, :, 0] = L.reshape((sz_x, sz_y))\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs\n",
    "\n",
    "\n",
    "def convert_RGB__and_augment_to_feed_model(img):\n",
    "    img = np.asarray(img)\n",
    "    sz_x = img.shape[0]\n",
    "    sz_y = img.shape[1]\n",
    "\n",
    "    train_imgs = np.zeros((sz_x, sz_y, 2))\n",
    "    train_input = np.zeros((sz_x, sz_y, 1))\n",
    "\n",
    "    R1 = np.reshape(img[:, :, 0], (sz_x * sz_y, 1))\n",
    "    G1 = np.reshape(img[:, :, 1], (sz_x * sz_y, 1))\n",
    "    B1 = np.reshape(img[:, :, 2], (sz_x * sz_y, 1))\n",
    "    L, A, B = RGB2LAB(R1, G1, B1)\n",
    "\n",
    "    # Apply LTransformation to the L channel\n",
    "    L_transformation = LTransformation()\n",
    "    L_augmented, _, _, _ = L_transformation(L.reshape((sz_x, sz_y)))\n",
    "\n",
    "    train_input[:, :, 0] = L_augmented\n",
    "    train_imgs[:, :, 0] = np.reshape(A, (sz_x, sz_y))\n",
    "    train_imgs[:, :, 1] = np.reshape(B, (sz_x, sz_y))\n",
    "\n",
    "    return train_input, train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_transform(image):\n",
    "    L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_LAB_and_augment_transform(image):\n",
    "    if np.random.rand() < 0.25:  # only apply augmentation to 25% of the data\n",
    "        L, AB = convert_RGB__and_augment_to_feed_model(image)\n",
    "    else:\n",
    "        L, AB = convert_RGB_to_feed_model(image)\n",
    "    return (L, AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check info from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was initially created using the scripts `retrieve_data.ipynb` and stored in a private server for later (re)use.\n",
    "In the metadata.csv file we get the information on original link, class and coordinates of each image.\n",
    "\n",
    "NOTE: the following are links stored in a private server, jet they are still publically available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12960 entries, 0 to 12959\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   img_id      12960 non-null  int64  \n",
      " 1   img_name    12960 non-null  object \n",
      " 2   latitude    12960 non-null  float64\n",
      " 3   longitude   12960 non-null  float64\n",
      " 4   zoom_level  12960 non-null  int64  \n",
      " 5   class       12960 non-null  int64  \n",
      " 6   link        12960 non-null  object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 810.0+ KB\n"
     ]
    }
   ],
   "source": [
    "is_large_dataset = True\n",
    "\n",
    "if is_large_dataset:\n",
    "    server_port = 1986 # Large dataset of ~10K images\n",
    "else:\n",
    "    server_port = 1985 # Large dataset of ~10K images\n",
    "# server_port = 1985 # initial dataset of 3.6K images\n",
    "\n",
    "raw_data_csv_file_link = f\"https://perritos.myasustor.com:{server_port}/metadata.csv\"\n",
    "\n",
    "\n",
    "metadata_raw_df = pd.read_csv(raw_data_csv_file_link, index_col=0)\n",
    "metadata_raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Train, Valid and Test subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the column `image_id` from the metadata as index of the images and then we perform standard shufling and splitting.\n",
    "\n",
    "The final ratio for the train, validation and test dastasets are: 70, 29 and 1 % respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size fo the train dataset is: 7602.\n",
      "the size fo the validation dataset is: 3258.\n",
      "the size fo the test dataset is: 2100.\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = metadata_raw_df[\"img_id\"].to_list(), metadata_raw_df[\"class\"] .to_list()\n",
    "\n",
    "rand_state = 9898\n",
    "\n",
    "train_ratio = 0.5866\n",
    "validation_ratio = 0.2514\n",
    "test_ratio = 0.162\n",
    "\n",
    "\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio, stratify = dataY, random_state=rand_state)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), stratify=y_test, random_state=rand_state)\n",
    "\n",
    "print(f\"the size fo the train dataset is: {len(x_train)}.\\nthe size fo the validation dataset is: {len(x_val)}.\\nthe size fo the test dataset is: {len(x_test)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1\n",
    "\n",
    "# Instantiate the dataset\n",
    "# img_indices = [0, 1, 2, 3, 4, 5]  # Example indices\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_loader = SwisstopoDataset(x_test,\n",
    "                           transform=convert_to_LAB_transform,\n",
    "                           large_dataset=True,\n",
    "                           return_label=True,\n",
    "                           batch_size=b_size,\n",
    "                           shuffle=False)\n",
    "\n",
    "# train_dataset = train_dataset_loader.get_dataset()\n",
    "test_dataset = test_dataset_loader.get_dataset()\n",
    "# valid_dataset = valid_dataset_loader.get_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tf.data.Dataset\n",
    "# Iterate over the dataset\n",
    "# for batch in test_dataset:\n",
    "#     # (L_channel, AB_channels), labels = batch # print with labels\n",
    "#     # print(L_channel.shape, AB_channels.shape, print(labels.shape))\n",
    "#     L_channel, AB_channels= batch # print without labels\n",
    "#     print(L_channel.shape, AB_channels.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional info about the base *Hyper-U-Net* model can be found at the following sources:\n",
    "\n",
    "- link to [original paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9604844/)\n",
    "\n",
    "- link to [repository](https://github.com/3DOM-FBK/Hyper_U_Net?tab=readme-ov-file)\n",
    "\n",
    "- link to [model](\"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\")\n",
    "\n",
    "NOTE: This will download a multiples large files to your device in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if model is in the current directory otherwise download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: base_model\n",
      "URL: https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\n",
      "\n",
      "Model Name: HyperUnet_retrain_augmented_noise_corrected_Adam\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_Adam/HyperUnet_retrain_augmented_noise_corrected_Adam_ckpt_epoch27_valloss0.0234.keras\n",
      "\n",
      "Model Name: HyperUnet_retrain_no_augmented_corrected_Adam\n",
      "URL: https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_no_augmented_corrected_Adam/HyperUnet_retrain_no_augmented_corrected_Adam_ckpt_epoch27_valloss0.0230.keras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_sources = {\n",
    "    \"model_name\": [\n",
    "        \"base_model\",\n",
    "        # \"HyperUnet_retrained_30e\",\n",
    "        # \"HyperUnet_retrain_augmented_30e\",\n",
    "        # \"HyperUnet_retrain_augmented_noise_25e\",\n",
    "        \"HyperUnet_retrain_augmented_noise_corrected_Adam\",\n",
    "        # \"HyperUnet_retrain_augmented_noise_corrected_rmsprop\",\n",
    "        \"HyperUnet_retrain_no_augmented_corrected_Adam\",\n",
    "          ],\n",
    "    \"url\": [\n",
    "        \"https://drive.usercontent.google.com/download?id=19DaA9f1HIOW9PmUz11xKw65fCo3X7-Fw&export=download&authuser=0&confirm=t&uuid=8a03b6f8-6f5d-4bc8-a62d-8b0cfc98d2db&at=APZUnTU9WqjmYlQcAGh22O2M8wXI%3A1717452655512\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrained_30e/HyperUnet_retrain1.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented/HyperUnet_retrain_augmented_epoch30_valloss0.0011.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise/HyperUnet_retrain_augmented_noise_ckpt_epoch25_valloss0.0010.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_Adam/HyperUnet_retrain_augmented_noise_corrected_Adam_ckpt_epoch27_valloss0.0234.keras\",\n",
    "        # \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_augmented_noise_corrected_rmsprop/HyperUnet_retrain_augmented_noise_corrected_rmsprop_ckpt_epoch30_valloss0.0248.keras\",\n",
    "        \"https://perritos.myasustor.com:1986/Models/HyperUnet_retrain_no_augmented_corrected_Adam/HyperUnet_retrain_no_augmented_corrected_Adam_ckpt_epoch27_valloss0.0230.keras\"\n",
    "        ],\n",
    "    \"extension\": [\n",
    "        \"h5\",\n",
    "        # \"keras\",\n",
    "        # \"keras\",\n",
    "        # \"keras\",\n",
    "        \"keras\",\n",
    "        # \"keras\",\n",
    "        \"keras\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    model_name = models_sources[\"model_name\"][i]\n",
    "    url = models_sources[\"url\"][i]\n",
    "    print(f\"Model Name: {model_name}\\nURL: {url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n",
      "########### No model to load, everything is in the current directory ##############\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    file_name = models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]\n",
    "    if not os.path.exists(os.path.join(os.curdir,file_name)):\n",
    "        model_url = models_sources['url'][i]\n",
    "        # !wget -O {file_name}  \"$model_url\"\n",
    "        request.urlretrieve(model_url, file_name)\n",
    "    else:\n",
    "        print(\"########### No model to download, everything is in the current directory ##############\")\n",
    "    # !wget -O {models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]} {models_sources[\"url\"][i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** loading 'base_model.h5' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubencito/micromamba/envs/colorization/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_augmented_noise_corrected_Adam.keras' *****\n",
      "***** done *****\n",
      "***** loading 'HyperUnet_retrain_no_augmented_corrected_Adam.keras' *****\n",
      "***** done *****\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {}\n",
    "\n",
    "for i in range(len(models_sources[next(iter(models_sources.keys()))])):\n",
    "    file_name = models_sources[\"model_name\"][i] + \".\" + models_sources[\"extension\"][i]\n",
    "    # print(f\"{'*'*5} loading '{models_sources['model_name'][i]}' {'*'*5}\")\n",
    "    print(f\"{'*'*5} loading '{file_name}' {'*'*5}\")\n",
    "    models[models_sources[\"model_name\"][i]] = load_model(file_name)\n",
    "    print(f\"{'*'*5} done {'*'*5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the main loop to compute the metrics.\n",
    "\n",
    "- We use the *Test* tadates of about 100 images.\n",
    "\n",
    "- First we pass the L channel (grey image) to the model to make the prediction.\n",
    "\n",
    "- Then we transform the **original** AND the **predicted** L\\*a\\*b images to RGB colorspace and plot them to compare results.\n",
    "\n",
    "- Finally we compute a number of metrics and summarize the results in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model': <Functional name=model, built=True>,\n",
       " 'HyperUnet_retrain_augmented_noise_corrected_Adam': <Functional name=model, built=True>,\n",
       " 'HyperUnet_retrain_no_augmented_corrected_Adam': <Functional name=model, built=True>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_imgs_to_test = len(test_dataset)\n",
    "def evaluate_model_metrics(dataset, model, model_name, n_samples):\n",
    "\n",
    "    sample = dataset.take(n_samples)\n",
    "    deltaE_list = []\n",
    "    MAE_list = []\n",
    "    PSNR_list = []\n",
    "    SSIM_list = []\n",
    "\n",
    "    for indx, data in enumerate(tqdm(sample, desc = f\"evaluating model: '{model_name}'\", total=n_samples)):\n",
    "\n",
    "        (L, AB), label = data\n",
    "        # print(type(L))\n",
    "        # # L = tf.squeeze(L)\n",
    "        # print(L.shape)\n",
    "        # print(type(AB))\n",
    "        # print(AB.shape)\n",
    "        # print(type(label))\n",
    "        # print(label.shape)\n",
    "        # my_model = models[\"base_model\"]\n",
    "        predicted_AB = model.predict(L, verbose=0)\n",
    "        predicted_RGB = from_LAB_to_RGB_img(L[0, ...], predicted_AB)\n",
    "        original_RGB = from_LAB_to_RGB_img(L[0, ...], AB)\n",
    "        # print(f\"Shape of original RGB is :{original_RGB.shape}\")\n",
    "        # print(\"*** Computing metrics ***\")\n",
    "        MAE = mae(original_RGB,predicted_RGB,3)\n",
    "        PSNR= psnr(original_RGB,predicted_RGB)\n",
    "        SSIM, _ = ssim(original_RGB, predicted_RGB, channel_axis=2, full=True) # NOTE: need to specify axis channels, otherwise complains!\n",
    "\n",
    "\n",
    "        \n",
    "        deltaE = compute_delta_e_cie2000(original_RGB, predicted_RGB)\n",
    "                    \n",
    "        MAE_list.append(MAE)\n",
    "        SSIM_list.append(SSIM)\n",
    "        PSNR_list.append(PSNR)\n",
    "        deltaE_list.append(deltaE)\n",
    "\n",
    "\n",
    "    metrics_dict = {\n",
    "    \"Model\": model_name,\n",
    "    \"dE2000\": deltaE_list,\n",
    "    \"MAE\" : MAE_list,\n",
    "    \"PSNR\" : PSNR_list,\n",
    "    \"SSIM\" : SSIM_list,\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start the metrics evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** assesing model: 'base_model' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'base_model': 100%|██████████| 100/100 [01:04<00:00,  1.57it/s]2024-07-27 01:21:41.388586: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'base_model': 100%|██████████| 100/100 [01:04<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** assesing model: 'HyperUnet_retrain_augmented_noise_corrected_Adam' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_Adam':   0%|          | 0/100 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722036102.592343  371577 service.cc:145] XLA service 0x7f95942e3eb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722036102.592389  371577 service.cc:153]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1722036103.365173  371577 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_Adam': 100%|██████████| 100/100 [01:18<00:00,  1.31it/s]2024-07-27 01:22:59.468042: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'HyperUnet_retrain_augmented_noise_corrected_Adam': 100%|██████████| 100/100 [01:18<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n",
      "***** assesing model: 'HyperUnet_retrain_no_augmented_corrected_Adam' *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating model: 'HyperUnet_retrain_no_augmented_corrected_Adam': 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]2024-07-27 01:24:18.320472: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "evaluating model: 'HyperUnet_retrain_no_augmented_corrected_Adam': 100%|██████████| 100/100 [01:18<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** done *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_all_list = []\n",
    "\n",
    "for indx, model in enumerate(models):\n",
    "    print(f\"{'*'*5} assesing model: '{model}' {'*'*5}\")\n",
    "    # if indx > 0:\n",
    "    # for sample in tqdm(data_to_test):\n",
    "    result = evaluate_model_metrics(dataset = test_dataset, model=models[model], model_name=model, n_samples = 100)\n",
    "\n",
    "    metrics_all_list.append(result)\n",
    "    print(f\"{'*'*5} done {'*'*5}\")\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap and reformat results in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Model   300 non-null    object \n",
      " 1   dE2000  300 non-null    float64\n",
      " 2   MAE     300 non-null    float64\n",
      " 3   PSNR    300 non-null    float64\n",
      " 4   SSIM    300 non-null    float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# numeric_columns = [\"MSE\", \"PSNR\", \"MSEr\", \"MSEg\", \"MSEb\", \"RMSE\", \"SSIM\"]\n",
    "numeric_columns = [\"dE2000\", \"MAE\", \"PSNR\", \"SSIM\"]\n",
    "metrics_df = pd.DataFrame(metrics_all_list).explode(numeric_columns, ignore_index=True)\n",
    "metrics_df[numeric_columns] = metrics_df[numeric_columns].astype(float)\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('_', ' ')\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('corrected', ' ')\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('retrain', ' ')\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('noise', ' ')\n",
    "# metrics_df['Model'] = [f\"Model{i}\" for i in range(8)]\n",
    "metrics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x19665f350>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_grouped = metrics_df.groupby(\"Model\", as_index=False)\n",
    "metrics_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented     Adam</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.36</td>\n",
       "      <td>33.27</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>1.19</td>\n",
       "      <td>4.15</td>\n",
       "      <td>33.56</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base model</td>\n",
       "      <td>2.08</td>\n",
       "      <td>10.75</td>\n",
       "      <td>25.27</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  dE2000    MAE   PSNR  SSIM\n",
       "0   HyperUnet   augmented     Adam    1.22   4.36  33.27  0.99\n",
       "1  HyperUnet   no augmented   Adam    1.19   4.15  33.56  0.99\n",
       "2                       base model    2.08  10.75  25.27  0.97"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# metrics_df.groupby(\"Model\", as_index=False).mean().round(2).to_csv(\"metrics_df_mean.csv\", index=False)\n",
    "metrics_df_mean = metrics_df_grouped.mean().round(2)\n",
    "# metrics_df_mean[\"Model\"] = [f\"Model{i}\" for i in range(7)]\n",
    "# metrics_df_mean.to_csv(\"metrics_df_mean.csv\", index=False)\n",
    "metrics_df_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented     Adam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base model</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  dE2000  MAE  PSNR  SSIM\n",
       "0   HyperUnet   augmented     Adam     1.0  1.8   2.8   0.0\n",
       "1  HyperUnet   no augmented   Adam     1.0  1.5   2.8   0.0\n",
       "2                       base model     1.4  3.9   3.3   0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics_df_std = metrics_df_grouped.std().round(1)\n",
    "# metrics_df_mean[\"Model\"] = [f\"Model{i}\" for i in range(7)]\n",
    "# metrics_df_std.to_csv(\"metrics_std.csv\", index=False)\n",
    "metrics_df_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented     Adam</td>\n",
       "      <td>1.22±1.0</td>\n",
       "      <td>4.36±1.8</td>\n",
       "      <td>33.27±2.8</td>\n",
       "      <td>0.99±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>1.19±1.0</td>\n",
       "      <td>4.15±1.5</td>\n",
       "      <td>33.56±2.8</td>\n",
       "      <td>0.99±0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base model</td>\n",
       "      <td>2.08±1.4</td>\n",
       "      <td>10.75±3.9</td>\n",
       "      <td>25.27±3.3</td>\n",
       "      <td>0.97±0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model    dE2000        MAE       PSNR      SSIM\n",
       "0   HyperUnet   augmented     Adam  1.22±1.0   4.36±1.8  33.27±2.8  0.99±0.0\n",
       "1  HyperUnet   no augmented   Adam  1.19±1.0   4.15±1.5  33.56±2.8  0.99±0.0\n",
       "2                       base model  2.08±1.4  10.75±3.9  25.27±3.3  0.97±0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics_df_mean_plus_std = metrics_df_mean.iloc[:, 1:].astype(str) + u\"\\u00B1\" + metrics_df_std.iloc[:, 1:].astype(str)\n",
    "metrics_df_mean_plus_std.insert(0, \"Model\", metrics_df_mean.iloc[:, 0])\n",
    "metrics_df_mean_plus_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df_mean_plus_std.to_csv(\"metrics_df_mean_plus_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate FID score\n",
    "Adapted from this [sorce](https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/) to calculate FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of calculating the frechet inception distance in Keras for cifar10\n",
    "# import numpy\n",
    "# from numpy import cov\n",
    "# from numpy import trace\n",
    "# from numpy import iscomplexobj\n",
    "# from numpy import asarray\n",
    "\n",
    "# from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(dataset, model, model_name, n_samples):\n",
    "\n",
    "    original_imgs_stack = []\n",
    "    predicted_imgs_stack = []\n",
    "\n",
    "    # n_samples = 2100\n",
    "    sample = dataset.take(n_samples)\n",
    "\n",
    "    for data in tqdm(sample, desc = f\"evaluating model: '{model_name}'\", total=n_samples):\n",
    "        (L, AB), label = data\n",
    "        predicted_AB = model.predict(L, verbose=0)\n",
    "        predicted_RGB = from_LAB_to_RGB_img(L[0, ...], predicted_AB)\n",
    "        predicted_imgs_stack.append(predicted_RGB)\n",
    "        # print(f\"type predicted_RGB: '{type(predicted_RGB)}'. size: {predicted_RGB.shape}\")\n",
    "        \n",
    "        original_RGB = from_LAB_to_RGB_img(L[0, ...], AB)\n",
    "        original_imgs_stack.append(original_RGB)\n",
    "        # print(f\"type original_RGB: '{type(original_RGB)}'. size: {original_RGB.shape}\")\n",
    "        # print(f\"{'*'*5} Done {'*'*5}\")\n",
    "        # break\n",
    "    \n",
    "    return (np.array(original_imgs_stack), np.array(predicted_imgs_stack))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orignal_imgs, predicted_imgs = predict_images(data_to_test, models[\"base_model\"], \"base_model\", n_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orignal_imgs.shape, predicted_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.apply_over_axes(func = mae, a=[orignal_imgs, predict_images], axes=0)\n",
    "# np.apply_along_axis(psnr, 0, orignal_imgs,  predict_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "\timages_list = list()\n",
    "\tfor image in images:\n",
    "\t\t# resize with nearest neighbor interpolation\n",
    "\t\tnew_image = resize(image, new_shape, 0)\n",
    "\t\t# store\n",
    "\t\timages_list.append(new_image)\n",
    "\treturn np.asarray(images_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste = scale_images(orignal_imgs, (299,299,3))\n",
    "# teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate frechet inception distance\n",
    "def calculate_fid(images1, images2, on_model):\n",
    "\t\n",
    "\tmodel = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "\timages1 = images1.astype('float32')\n",
    "\timages2 = images2.astype('float32')\n",
    "\t# resize images\n",
    "\timages1 = scale_images(images1, (299,299,3))\n",
    "\timages2 = scale_images(images2, (299,299,3))\n",
    "\tprint('Scaling images', images1.shape, images2.shape)\n",
    "\t# pre-process images\n",
    "\timages1 = preprocess_input(images1) # preprare the data to adjusted for the model input. see reference here: https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input\n",
    "\timages2 = preprocess_input(images2)\n",
    "\n",
    "\t# calculate activations\n",
    "\tact1 = model.predict(images1)\n",
    "\tact2 = model.predict(images2)\n",
    "\t# calculate mean and covariance statistics\n",
    "\tmu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "\tmu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "\t# calculate sum squared difference between means\n",
    "\tssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "\t# calculate sqrt of product between cov\n",
    "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
    "\t# check and correct imaginary numbers from sqrt\n",
    "\tif np.iscomplexobj(covmean):\n",
    "\t\tcovmean = covmean.real\n",
    "\t# calculate score\n",
    "\tfid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "\tprint('FID: %.3f' % fid)\n",
    "\tfid = {\"Model\": model_name,\n",
    "\t\t   \"FID\": round(fid, 2)}\n",
    "\treturn fid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_fid(orignal_imgs, predicted_imgs, \"lalala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_metrics_list = []\n",
    "\n",
    "for indx, model_name in enumerate(models):\n",
    "    print(f\"{'*'*5} computing FID on model: '{model_name}' {'*'*5}\")\n",
    "    # if indx > 0:\n",
    "    # for sample in tqdm(data_to_test):\n",
    "    # result = calculate_fid(data_to_test, models[model], model, n_samples)\n",
    "    orignal_imgs, predicted_imgs = predict_images(test_dataset, models[model_name], model_name, n_samples=2100)\n",
    "    FID_metrics_list.append(calculate_fid(orignal_imgs, predicted_imgs, model_name))\n",
    "    \n",
    "    print(f\"{'*'*5} done {'*'*5}\")\n",
    "\n",
    "FID_metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_df = pd.DataFrame(FID_metrics_list)\n",
    "FID_df['Model'] = FID_df['Model'].str.replace('_', ' ')\n",
    "FID_df['Model'] = FID_df['Model'].str.replace('corrected', ' ')\n",
    "FID_df['Model'] = FID_df['Model'].str.replace('retrain', ' ')\n",
    "FID_df['Model'] = FID_df['Model'].str.replace('noise', ' ')\n",
    "\n",
    "FID_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_mean_plus_std = pd.merge(metrics_df_mean_plus_std, FID_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_mean_plus_std.to_csv(\"metrics_df_mean_plus_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dE2000</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PSNR</th>\n",
       "      <th>SSIM</th>\n",
       "      <th>FID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperUnet   augmented     Adam</td>\n",
       "      <td>1.22±1.0</td>\n",
       "      <td>4.36±1.8</td>\n",
       "      <td>33.27±2.8</td>\n",
       "      <td>0.99±0.0</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HyperUnet   no augmented   Adam</td>\n",
       "      <td>1.19±1.0</td>\n",
       "      <td>4.15±1.5</td>\n",
       "      <td>33.56±2.8</td>\n",
       "      <td>0.99±0.0</td>\n",
       "      <td>21.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base model</td>\n",
       "      <td>2.08±1.4</td>\n",
       "      <td>10.75±3.9</td>\n",
       "      <td>25.27±3.3</td>\n",
       "      <td>0.97±0.0</td>\n",
       "      <td>40.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model    dE2000        MAE       PSNR      SSIM  \\\n",
       "0   HyperUnet   augmented     Adam  1.22±1.0   4.36±1.8  33.27±2.8  0.99±0.0   \n",
       "1  HyperUnet   no augmented   Adam  1.19±1.0   4.15±1.5  33.56±2.8  0.99±0.0   \n",
       "2                       base model  2.08±1.4  10.75±3.9  25.27±3.3  0.97±0.0   \n",
       "\n",
       "     FID  \n",
       "0  21.02  \n",
       "1  21.12  \n",
       "2  40.32  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_mean_plus_std = pd.read_csv(\"metrics_df_mean_plus_std.csv\")\n",
    "# metrics_df_mean_plus_std.round(2).to_csv(\"metrics_df_mean_plus_std.csv\", index=False)\n",
    "# metrics_df_mean_plus_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Model   3 non-null      object \n",
      " 1   dE2000  3 non-null      object \n",
      " 2   MAE     3 non-null      object \n",
      " 3   PSNR    3 non-null      object \n",
      " 4   SSIM    3 non-null      object \n",
      " 5   FID     3 non-null      float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 276.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# metrics_df_mean_plus_std.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
